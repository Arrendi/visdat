---
title: "Using visdat"
author: "Nicholas Tierney"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# visdat

# What does visdat do?

Initially inspired by [`csv-fingerprint`](https://github.com/setosa/csv-fingerprint), `vis_dat` helps visualise a dataframe in a heatmap-like fashion, allowing you to "get a look at the data", by displaying the variable classes in a dataframe as a plot with `vis_dat`, and getting a brief look into missing data patterns `vis_miss`.

There have been 6 phases of data science [1](http://r4ds.had.co.nz/introduction.html) described, being:

[image from this datascience page with reference]()

Where Wickham describes that you can get insight into your data by modelling, visualising, and transforming, which he describes as "Understanding" or "knowledge generation". There is some overlap here, as in this process it wouldn't be surprising that you might uncover some feature of your dataset that you would need to clean up - you might discover that some strings were indeed factors, or that gender was considered numeric in your regression, warranting you to re-visit the Tidying phase.

In the same way, I think that this process gets applied in the Tidying step of data science. You read in your data, but you then need to look at it to understand what you need to do to "fix it". And that's a key phrase here "looking at the data" - what does that mean?

On one hand, you can look at the head of the data:

```{r}

head(iris)

```

Or you can have a `glimpse` at it through `tibble`/`dplyr`

```{r}

tibble::glimpse(iris)

```

And we can see we have doubles, and a factor. And we get a little insight into the data.

But we don't always have data like iris, let's take a look at some data that might be a bit more typical of "messy" data.

```{r}
library(visdat)
dplyr::glimpse(typical_data)

```

And you might then ask:

> Isn't it odd that Income is  afactor? And Age is a character? 

```{r}



```


The name `visdat` was chosen as it borrows from the idea of [`testdat`](https://github.com/ropensci/testdat), which provides unit testing for your data.  In a similar way, `visdat` provides visual tests for The idea being that first you visualise your data (`visdat`), then you run tests from `testdat` to fix them.

There are currently three main commands: `vis_dat`, `vis_miss`, and `vis_guess`

- `vis_dat` visualises a dataframe showing you what the classes of the columns are, and also displaying the missing data.

- `vis_miss` visualises just the missing data, and allows for missingness to be clustered and columns rearranged. `vis_miss` is similar to `missing.pattern.plot` from the `mi` package. Unfortunately `missing.pattern.plot` is no longer in the `mi` package (well, as of 14/02/2016).

-  `vis_guess` has a guess at what the value of each cell. So "10.1" will return "double", and `10.1` will return "double", and `01/01/01` will return "date". Keep in mind that it is a **guess** at what each cell is, so you can't trust this fully. `vis_guess` is made possible thanks to Hadley Wickham's `readr` package - thanks mate!


# How to install

```{r eval = FALSE}
# install.packages("devtools")

library(devtools)

install_github("njtierney/visdat")

```

# Examples

## Using `vis_dat`

Let's see what's inside the dataset `airquality`

```{r vis_dat}

library(visdat)

vis_dat(airquality)

```

The classes are represented on the legend, and missing data represented by grey. 

by default, `vis_dat` sorts the columns according to the type of the data in the vectors. You can turn this off by setting `sort_type == FALSE`. This feature is better illustrated using the `typical_data` dataset, created using [wakefield](github.com/trinker/wakefield) and contained within visdat

```{r}

vis_dat(typical_data)

vis_dat(typical_data, 
        sort_type = FALSE)

```

The plot above tells us that R reads this dataset as having numeric and integer values, along with some missing data in `Ozone` and `Solar.R`.

## using `vis_miss`

We can explore the missing data further using `vis_miss`

```{r vis_miss}

vis_miss(airquality)

```

The percentages of missing/complete in `vis_miss` are accurate to 1 decimal place.

You can cluster the missingness by setting `cluster = TRUE`

```{r vis_miss-cluster}

vis_miss(airquality, 
         cluster = TRUE)

```

The columns can also just be arranged by columns with most missingness, by setting `sort_miss = TRUE`.

```{r}

vis_miss(airquality,
         sort_miss = TRUE)

```

When there is <0.1% of missingness, `vis_miss` indicates that there is >1% missingness.

```{r}

test_miss_df <- data.frame(x1 = 1:10000,
                           x2 = rep("A", 10000),
                           x3 = c(rep(1L, 9999), NA))

vis_miss(test_miss_df)

```

`vis_miss` will also indicate when there is no missing data at all

```{r}

vis_miss(mtcars)

```

## using `vis_guess`

`vis_guess` takes a guess at what each cell is. It's best illustrated using some messy data, which we'll make here.

```{r}

messy_vector <- c(TRUE,
                  T,
                  "TRUE",
                  "T",
                  "01/01/01",
                  "01/01/2001",
                  NA,
                  NaN,
                  "NA",
                  "Na",
                  "na",
                  "10",
                  10,
                  "10.1",
                  10.1,
                  "abc",
                  "$%TG")

messy_df <- data.frame(var1 = messy_vector,
                       var2 = sample(messy_vector),
                       var3 = sample(messy_vector))

```


```{r}

vis_guess(messy_df)

```

So here we see that there are many different kinds of data in your dataframe. As an analyst this might be a depressing finding. Compare this to `vis_dat`.

```{r}

vis_dat(messy_df)

```

Where you'd just assume your data is wierd because it's all factors - or worse, not notice that this is a problem.

At the moment `vis_guess` is very slow. Please take this into consideration when you are using it on data with more than 1000 rows. We're looking into ways of making it faster, potentially using methods from the `parallel` package, or extending the c++ code from `readr:::collectorGuess`.

# Interactivity

Thanks to Carson Sievert, you can now add some really nifty interactivity into visdat by using `plotly::ggplotly`, allowing for information to be revealed upon mouseover of a cell. The code to do this can be seen below, but is not shown as the github README doesn't support HTML interactive graphics...yet.

```{r eval = FALSE}

library(plotly)

vis_dat(airquality) %>% ggplotly()

```

# Road Map

**visualising expectations**

The idea here is to pass expectations into `vis_dat` or `vis_miss`, along the lines of the `expectation` command in `assertr`. For example, you could ask `vis_dat` to identify those cells with values of -1 with something like this:

```{r eval = FALSE}

data %>% 
  expect(value == -1) %>%
  vis_dat

```

