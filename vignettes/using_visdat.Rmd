---
title: "Using visdat"
author: "Nicholas Tierney"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, echo = FALSE}

knitr::opts_chunk$set(fig.width = 5,
                      fig.height = 4)

```


# visdat

# What does visdat do?

Initially inspired by [`csv-fingerprint`](https://github.com/setosa/csv-fingerprint), `vis_dat` helps visualise a dataframe in a heatmap-like fashion, allowing you to "get a look at the data", by displaying the variable classes in a dataframe as a plot with `vis_dat`, and getting a brief look into missing data patterns `vis_miss`.

In his [R for Data Science book](http://r4ds.had.co.nz/), Wickham describes 6 phases of data science:

![Process of Data Science](http://r4ds.had.co.nz/diagrams/data-science.png)


You can get insight into your data by modelling, visualising, and transforming, which Wickham describes as "Understanding" or "knowledge generation". There is some overlap here, as in this process it wouldn't be surprising that you might uncover some feature of your dataset that you would need to clean up - you might discover that some strings were indeed factors, or that gender was considered numeric in your regression, warranting you to re-visit the Tidying phase.

In the same way, I think that this process gets applied in the Tidying step of data science. You read in your data, but you then need to look at it to understand what you need to do to "fix it". And that's a key phrase here "looking at the data" - what does that mean?

On one hand, you can look at the head of the data:

```{r head-iris}

head(iris)

```

Or you can have a `glimpse` at it through `dplyr::glimpse`

```{r glimpse}

dplyr::glimpse(iris)

```

Here we see that we have doubles, and a factor. We get some insight into the data.

But we don't always have data like the canonical iris dataset. :et's take a look at some data that might be a bit more typical of "messy" data.

```{r visdat-glimpse}
library(visdat)
dplyr::glimpse(typical_data)

```

Looking at this, you might then ask:

> Isn't it odd that Income is a factor? And Age is a character? 

And you might start to wonder what else is different, what else changed? 

the `visdat` package provides the functions `vis_dat()` to help explore the data class structure and missingness:

```{r load-data}

vis_dat(typical_data)

```

And the separate `vis_miss` function to provide specialised insight into missing data

```{r}

vis_miss(typical_data)

```


The name `visdat` was chosen as it borrows from the idea of [`testdat`](https://github.com/ropensci/testdat), which provides unit testing for your data.  In a similar way, `visdat` provides visual tests for The idea being that first you visualise your data (`visdat`), then you run tests from `testdat` to fix them.

## Using `vis_dat`

Let's see what's inside the dataset `airquality`

```{r vis_dat}

library(visdat)

vis_dat(airquality)

```

The classes are represented on the legend, and missing data represented by black. By default, `vis_dat` sorts the columns according to the type of the data in the vectors. You can turn this off by setting `sort_type == FALSE`. This feature is better illustrated using the `typical_data` dataset, created using [wakefield](github.com/trinker/wakefield) and contained within visdat

```{r visdat-typical}

vis_dat(typical_data)

vis_dat(typical_data, 
        sort_type = FALSE)

```

The plot above tells us that R reads this dataset as having numeric and integer values, along with some missing data in `Ozone` and `Solar.R`.

## using `vis_miss`

We can explore the missing data further using `vis_miss`

```{r vis_miss}

vis_miss(airquality)

```

The percentages of missing/complete in `vis_miss` are accurate to 1 decimal place.

You can cluster the missingness by setting `cluster = TRUE`

```{r vis_miss-cluster}

vis_miss(airquality, 
         cluster = TRUE)

```

The columns can also just be arranged by columns with most missingness, by setting `sort_miss = TRUE`.

```{r vismiss}

vis_miss(airquality,
         sort_miss = TRUE)

```

When there is <0.1% of missingness, `vis_miss` indicates that there is >1% missingness.

```{r vismiss-new-data}

test_miss_df <- data.frame(x1 = 1:10000,
                           x2 = rep("A", 10000),
                           x3 = c(rep(1L, 9999), NA))

vis_miss(test_miss_df)

```

`vis_miss` will also indicate when there is no missing data at all. For example the `mtcars` dataset has no missing data.

```{r vismiss-mtcars}

vis_miss(mtcars)

```

To explore the missingness structure in a dataset, I recommend the [`naniar`](https://github.com/njtierney/naniar) package, which provides more general tools for graphical and numerical exploration of missing values.

## using `vis_guess`

`vis_guess` takes a guess at what each cell is. It's best illustrated using some messy data, which we'll make here.

```{r create-messy-vector}

messy_vector <- c(TRUE,
                  T,
                  "TRUE",
                  "T",
                  "01/01/01",
                  "01/01/2001",
                  NA,
                  NaN,
                  "NA",
                  "Na",
                  "na",
                  "10",
                  10,
                  "10.1",
                  10.1,
                  "abc",
                  "$%TG")

messy_df <- data.frame(var1 = messy_vector,
                       var2 = sample(messy_vector),
                       var3 = sample(messy_vector))

```

Here if we just glimpse `messy_df`, we get 

```{r}

dplyr::glimpse(messy_df)

```

It looks like we have 3 factors. But this seems a bit strange. `vis_guess` takes a guess at what each element is, visualising it for you:

```{r messy-vis-guess}

vis_guess(messy_df)

```

So here we see that there are many different kinds of data in your dataframe. As an analyst this might be a depressing finding. Compare this to `vis_dat`.

```{r visdat-messy}

vis_dat(messy_df)

```

Where you'd just assume your data is wierd because it's all factors - or worse, not notice that this is a problem.

At the moment `vis_guess` is very slow. Please take this into consideration when you are using it on data with more than 1000 rows. We're looking into ways of making it faster, potentially using methods from the `parallel` package, or extending the c++ code from `readr:::collectorGuess`.

# Interactivity

Thanks to Carson Sievert, you can now add some really nifty interactivity into visdat by using `plotly::ggplotly`, allowing for information to be revealed upon mouseover of a cell. The code to do this can be seen below, but is not shown as the github README doesn't support HTML interactive graphics...yet.

```{r plotly-example}

library(plotly)

vis_dat(airquality) %>% ggplotly()
```
